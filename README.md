 DocuChat AI Â· Multimodal RAG (Text Â· Image Â· Audio)

A Streamlit-based Multimodal Retrieval-Augmented Generation (RAG) system that indexes text, images, and audio into a shared CLIP embedding space.
It retrieves contextually relevant data and generates grounded, cited answersâ€”all without external FFmpeg dependencies.

> âš ï¸ For research and educational use only Â· Not for commercial deployment.

-----

ğŸš€ Features

  - ğŸ” Unified multimodal search â€” query by text, image, or audio.
  - ğŸ§  CLIP + FAISS backbone for vector similarity search across modalities.
  - ğŸ”Š Whisper integration for automatic speech-to-text on uploaded or YouTube audio.
  - ğŸ“„ Document support: PDF, TXT, DOCX, web pages, and YouTube captions.
  - ğŸ¥ FFmpeg-free audio decoding: uses PyAV and SoundFile only (works in restricted environments).
  - ğŸ’¡ Grounded answers with citations via Llama 3 (Ollama LLM backend).
  - ğŸŒ Robust YouTube pipeline with format fallback and duration validation.

-----

# ğŸ§° Tech Stack

| Category | Technology |
|-----------|-------------|
| Framework | Streamlit |
| Embeddings | Sentence-Transformers (clip-ViT-B-32) |
| Indexing | FAISS (Inner Product search + L2 normalization) |
| LLM | Ollama (Llama 3 models) |
| Audio Decode | PyAV + SoundFile (no external FFmpeg) |
| Speech to Text | Whisper |
| Document Parsing | LangChain Loaders (PyPDF, Text, Docx2txt) |
| Video/Audio Input | yt-dlp (YouTube download + validation) |

-----

